{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **Transformation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* Having extracted and examined the data in Extraction.ipynb and with y-data profile we will use this notebook to transform the data.\n",
        "    Columns of Interest for potential transformation:\n",
        "    *  Marital status and sex - both have unknown values which need to be handled\n",
        "    *  Attrition flag should be transformed from text to either boolean or numeric (potentially add new columns or separate datasets for attrited/ existing cutomers)\n",
        "    *  Some columns have outliers such as Credit_Limit and Avg_Open_To_Buy decide how to deal with these and if any transformation is necessary.\n",
        "    *  Other columns will need to be dropped as they are not relevant to project (Both Naive_Bayes columns for example)\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* We will be using the raw BankChurners.ipynb as the main input\n",
        "* The project hypotheses as documented in README \n",
        "\n",
        "## Outputs\n",
        "\n",
        "* A cleaned and transformed csv file\n",
        "* Visualisations to support the transformation process\n",
        "* Dialogue to show rationale for any transformation\n",
        "\n",
        "## Additional Comments\n",
        "\n",
        "* While most transformation will be completed in this notebook - some may also take place in powerBI with the cleaned CSV file (adding or renaming columns for example). These changes will be documented in this notebbok.\n",
        " \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We are assuming you will store the notebooks in a subfolder, therefore when running the notebook in the editor, you will need to change the working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "We want to make the parent of the current directory the new current directory\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Import all the Python libraries required to carry out ETL (Extract, Transform, Load) and EDA (Exploratory Data Analysis)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.pipeline import Pipeline # For building machine learning pipelines\n",
        "from feature_engine.selection import DropFeatures, DropDuplicateFeatures # For feature selection\n",
        "from feature_engine.imputation import MeanMedianImputer, CategoricalImputer # For handling missing data\n",
        "from feature_engine.imputation import ArbitraryNumberImputer # For handling missing data\n",
        "from feature_engine.encoding import OneHotEncoder, OrdinalEncoder # For encoding categorical variables\n",
        "from feature_engine.transformation import LogTransformer # For transforming numerical variables\n",
        "from feature_engine.outliers import Winsorizer # For handling outliers\n",
        "import joblib # For saving and loading models\n",
        "\n",
        "sns.set_theme(style=\"whitegrid\") # Set seaborn theme for plots\n",
        "pd.set_option('display.max_columns', None) # Display all columns in pandas DataFrames\n",
        "# random_state = 1 # For reproducibility\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "# Transform"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "1. Import the raw dataset (`BankChurners.csv`) into a DataFrame.\n",
        "2. Create a copy of the raw data to preserve the original.\n",
        "3. Check the datasetâ€™s dimensions (rows and columns).\n",
        "4. Preview the first few rows to understand the structure and content.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the raw data\n",
        "df_raw = pd.read_csv('Data/Raw/BankChurners.csv')\n",
        "\n",
        "# Make a copy of the raw data\n",
        "df = df_raw.copy()\n",
        "\n",
        "# Display the first few rows of the dataframe\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Initial Transformation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Section note"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltNetd085qHf"
      },
      "source": [
        "# Push files to Repo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* In cases where you don't need to push files to Repo, you may replace this section with \"Conclusions and Next Steps\" and state your conclusions and next steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKlnIozA4eQO",
        "outputId": "fd09bc1f-adb1-4511-f6ce-492a6af570c0"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# try:\n",
        "#   # create your folder here\n",
        "#   # os.makedirs(name='')\n",
        "# except Exception as e:\n",
        "#   print(e)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
